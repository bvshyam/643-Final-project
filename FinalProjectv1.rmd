---
title: "Recommender System : Amigo De Libro"
author: "Kumudini Bhave"
date: "July 5, 2017"
output:
  html_document:
    fontsize: 17pt
    highlight: pygments
    theme: cerulean
    toc: yes
    toc_float: yes
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: 3
---
     
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



*******

# **Recommender System : Amigo De Libro (Book Friend)**

********

## Summary


This is an R Markdown document for performing analysis of Book Crossing Data and to recommend the new / untried books of interest to users. 


```{r loadLib, warning=FALSE, comment=FALSE, message=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=150)}

knitr::opts_chunk$set(message = FALSE, echo=TRUE)

# Library for loading CSV data
library(RCurl)

# Library for data tidying
library(tidyr)

# Library for data structure operations 
suppressWarnings(suppressMessages(library(dplyr)))
suppressWarnings(suppressMessages(library(knitr)))
suppressWarnings(suppressMessages(library(stringr)))
suppressWarnings(suppressMessages(library(reshape2)))

# Library for plotting
library(ggplot2)

# Library for data display in tabular format
library(DT)
library(pander)

# Library for RecommenderSystem Algo
suppressWarnings(suppressMessages(library(recommenderlab)))


```


### Data Loading & Preparation

The Book Crossing dataset ,( courtesy,  mined by Cai-Nicolas Ziegler, DBIS Freiburg) was procured from  http://www2.informatik.uni-freiburg.de/~cziegler/BX/
The format is a CSV dump, that comprises of 3 datasets primarily of the User-Book Rating , Users Information and Books Information.


```{r loadData, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}


# Loading data from GitHub

# Working With Ratings Data First
# Since the size is large, we need to trim it to a manageable size

dfbookratings <- read.csv("https://raw.githubusercontent.com/bvshyam/643-Final-project/master/data/BX-Book-Ratings.csv", header=T, sep =";", stringsAsFactors = FALSE)
dim(dfbookratings)

# Rename columns for better handling
colnames(dfbookratings) <- c("user","isbn","rating")


# Getting User And Book Profile data

dfusers <- read.csv("https://raw.githubusercontent.com/bvshyam/643-Final-project/master/data/BX-Users.csv", header = TRUE, sep =";", stringsAsFactors = FALSE)

dfbooks <- read.csv("https://raw.githubusercontent.com/bvshyam/643-Final-project/master/data/BX-Books.csv", header = TRUE, sep =";", stringsAsFactors = FALSE)

# Renaming columns for better handling
colnames(dfusers) <- c("user","location","age")
colnames(dfbooks) <- c("isbn", "title","author","yearpub", "publisher", "iurls","iurlm", "iurll")

# Seggregating location in town, state, country for users
dfusers <- dfusers %>% separate(col = location, 
                                      into = c('town', 'state','country'), 
                                      sep = ",")
dfbooks <- dfbooks %>% select("isbn", "title","author","yearpub", "publisher","iurlm")
# Dimensions of the dataset are pretty large
dim(dfusers)
dim(dfbooks)


# Validating the rating data against users and books
combinedData <- merge(dfbookratings,dfbooks, by=c("isbn"))
combinedData <- merge(combinedData,dfusers, by=c("user"))
length(unique(combinedData$isbn)) # No of Unique ISBNs
length(unique(combinedData$user)) # No of Unique Users
dim(combinedData)

# Reduce dataset for users who have read 4 or more books, and books which are rated by at least 5 users, Long Format

dfbookratingsvalid <- combinedData %>% group_by(user) %>% filter(n()>4) %>% group_by(isbn) %>% filter(n()>5)
dim(dfbookratingsvalid)
length(unique(dfbookratingsvalid$isbn)) # No of Unique ISBNs after filtering
length(unique(dfbookratingsvalid$user)) # No of Unique Users after filtering


################### Wide Format Users ~ Books ####################

# Converting to Wide format to get User Book rating matrix
dfbookratingswide <- dfbookratingsvalid %>% select(user, isbn, rating) %>% spread(isbn, rating)%>%  arrange(user)
dim(dfbookratingswide)

# Storing users and books as rows and column  names
rownames(dfbookratingswide) <- dfbookratingswide$user
allusersrated <- rownames(dfbookratingswide) 
allbooksrated <- colnames(dfbookratingswide)
#View(dfbookratingswide)

# Free the memory
rm(dfbookratings)
rm(combinedData)


################### Wide Format Books ~ Users ####################
dfbookratingswidet <- dfbookratingswide %>% select(-user)

# Taking a transpose to have book (rows) by user (columns), This is wide format but books as rows and users as columns
dfbookratingswidet <-  t(dfbookratingswidet)
#The rownames and columns names are interchanges correctly
#View(head(dfbookratingswidet, 100))

dim(dfbookratingswidet)

# View sample of dataset

datatable(head(dfbookratingswide[1:10], 10))
datatable(head(dfusers, 10))
datatable(head(dfbooks, 10))

# We keep and refer only the books that are rated, hence putting that in a new books data set dfbooks2, after validating with the ratings data

bookIds <- unique(dfbooks$isbn) # unique books in book data
bookIdsRated <- unique(dfbookratingsvalid$isbn) # unique books actually rated 
dfbooks2 <- dfbooks[which((bookIds %in% bookIdsRated) == TRUE),] # Keep in the book data only those                                                                                       # rated , saved this in new book data set

# Store the isbns as rownames
rownames(dfbooks2) <- dfbooks2$isbn

# Free memory
rm(dfbooks)

# We now have,
# 1. dfbookratingsvalid  (Ratings Data Long format) , 
# 2. dfbookratingswide   (Ratings Data wide format user~books)
# 3. dfbookratingswidet  (Ratings Data wide format books~dfbooks2$yearpub)
# 4. dfusers             (User Data)
# 5. dfbooks2            (Book Data)


```





### ModelBase {.tabset}

#### Book-Book Decade Based Similarity Matrix

```{r decadebook, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}


# Finding number of unique features age of user
numAge <- length(unique(dfusers$age))


# Finding number of unique features publisher, author, year of publication to decide on content base

numPublisher <- length(unique(dfbooks2$publisher)) #313
numAuthor <- length(unique(dfbooks2$author)) #1161

dfbooks2$yearpub <- as.numeric(dfbooks2$yearpub )
numYearPub <- length(unique(dfbooks2$yearpub))

# Since no of unique yearpub is also large , 45 .. with 1 NAs, we can take the decade of publication, first imputing the yearpub with median values for all NAs and 0

# Imputing the year of publication null values with median value
dfbooks2$yearpub[is.na(dfbooks2$yearpub)] <- median(dfbooks2$yearpub, na.rm=TRUE)

# There are many books that have 0 as  the year of publication , we impute them as well for median values.
dfbooks2$yearpub[dfbooks2$yearpub == 0] <- median(dfbooks2$yearpub, na.rm=TRUE)



# Introduce Decade in place of Year:
decadeBoundary <- seq(1890, 2020, by = 10)

dfbooks2$year <- sapply(dfbooks2$yearpub, function(x) {
  wL <- x < decadeBoundary
  wU <- x >= decadeBoundary
  if (sum(wL) == length(decadeBoundary))  {
    return(1)
  } else if (sum(wU) == length(decadeBoundary)) {
    decadeBoundary[length(decadeBoundary)] 
  } else {
    decadeBoundary[max(which(wL-wU == -1))]
  }
}) 

numYear <- length(unique(dfbooks2$year))
# We have 6 distinct decades

#backup
dfbooksdata <- dfbooks2

# - Match Year with ratings data:
bookdec <- dfbooks2 %>% 
  select(isbn, year)
View(bookdec)
dfbookratingsvalid <- merge(dfbookratingsvalid, bookdec, by = 'isbn')#??

#View(dfbooksdata)
# Spread the year
dfbooksdata <- dfbooksdata %>%
  spread(key = year,
         value = year,
         fill = 0,
         sep = "_")
rownames(dfbooksdata) <- dfbooksdata$isbn
#View(dfbooksdata)

#dfbooksdata <- dfbooksdata %>% select(-)

library(text2vec)
# - compute moviesDistance:
booksDistance <- dfbooksdata[, 7:ncol(dfbooksdata)]

w <- which(booksDistance > 0, arr.ind = T)

booksDistance[w] <- 1

#booksDistance <- dist2(Matrix(as.matrix(dfbooksdata[, 7:ncol(dfbooksdata)])),                         method = "jaccard")

#booksDistance <- as.matrix(booksDistance)
View(booksDistance)
dim(booksDistance) #2407 by 6 2407 books
```





```{r storeuserbooknames, warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}

# Create binary rating matrix , makring > 4 ratings as +1 and 4 and lesser as -1
#binratings1 <- dfbookratingswidet

#for (i in 1:nrow(binratings1))
#{
#     for(j in 1:ncol(binratings1))
#     {
#          if( binratings1[i,j] > 4 )
#          {
#                    binratings1[i,j] <- 1
#          }
 #          else if(is.na(binratings1[i,j]))
 #              {
  #                  binratings1[i,j] <- -1
   #            }
    #       else   
     #          {
      #              binratings1[i,j] <- -1
       #        }
 #     }
#}
#



binratings <- dfbookratingsvalid

for (i in 1:nrow(binratings))
{
         if( binratings[i,3] > 4 )
          {
                    binratings[i,3] <- 1
          }
#           else if(is.na(binratings[i,3]))
#               {
#                    binratings[i,3] <- -1
#               }
           else   
               {
                    binratings[i,3] <- -1
               }
    
}
dim(binratings)
View(binratings)




# Converting to Wide format to get User Book rating matrix
binratingswide <- binratings %>% select( user, isbn,rating) %>% spread(isbn, rating)%>%  arrange(user)

rownames(binratingswide) <- binratingswide$user
binallusersrated <- rownames(binratingswide) 
binallbooksrated <- colnames(binratingswide)

dim(binratingswide)
View(binratingswide)

for (i in 1:ncol(binratingswide)){
  binratingswide[which(is.na(binratingswide[,i]) == TRUE),i] <- 0
}

binratingswidet <- binratingswide %>% select(-user) 

binratingswidet <- t(binratingswidet)
View(binratingswidet)
length(colnames(binratingswidet))




```



### Obtaining User Profile (For The Decade of Book Publication Year Feature)

```{r  warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}



#Calculate dot product for User Profiles
result = matrix(0,6,ncol(binratingswidet)) # As we are dealing with 6 decades (Feature : Year of Publication)

for (c in 1:ncol(binratingswidet)){
  for (i in 1:ncol(booksDistance)){
    result[i,c] <- sum((booksDistance[,i]) * (binratingswidet[,c]))
  }
}


dim(result)
 

##Convert to Binary scale
for (i in 1:nrow(result)){
  if (result[i] < 0){
    result[i] <- 0
  }
  else {
    result[i] <- 1
  }
}

#This user profiles shows the aggregated inclination of each user towards book publication decade. Each column represents a unique userId, and positive values shows a preference towards a certain decade.
```


Now, assuming that users like similar books, and we retrieve books that are closest in similarity to a user's profile, which represents a user's preference forthe books publication time(decade).

Using Jaccard Distance to measure the similarity between user profiles, and the book publication decade matrix. Jaccard Distance being suitable for binary data.








#### User User Similarity Matrix
Using the proxy::dist() functionto calculate Jaccard Distance. 
It calculates the distance between rows from a single matrix, hence  with 2 matrices, we run over a loop and each time ,  combine the genre matrix with the user profile matrix one rec at a time, and retrieve the minimum distance for each user. 

```{r  warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}

resulteachuser <- result[1,] #First user's profile
sim_mat <- rbind.data.frame(resulteachuser, booksDistance)
sim_mat <- data.frame(lapply(sim_mat,function(x){as.integer(x)})) #convert data to type integer
 


#Calculate Jaccard distance between user profile and all movies
library(proxy)
sim_results <- dist(sim_mat, method = "Jaccard")
sim_results <- as.data.frame(as.matrix(sim_results[1:nrow(binratingswidet)])) # for n no of books,                                                                                 ie 2364 books
rows <- which(sim_results == min(sim_results))
#Recommended movies
dfbooks2[rows,1:6]



#############################


```

![](`r dfbooks2[rows, 6]`)







### Matrix Factorization
```{r  warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}




#r <- matrix(1,20,10) 20 b * 10 user
#b <- matrix(2,20,5)





```





### Calculate RMSE

```{r  warning=FALSE, tidy=TRUE, tidy.opts=list(width.cutoff=80),echo=TRUE}


#model_als.RMSE <- sqrt(mean((predictions$rating-predictions$prediction)^2))
#model_als.RMSE
```


*********

### Summary Of Learnings



#### Reference

******
